{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FMI Hirlam, MET Norway HARMONIE and NCEP GFS comparison demo\n",
    "\n",
    "In this demo notebook we provide short comparison of using three different weather forecast models:\n",
    "GFS -- http://data.planetos.com/datasets/noaa_gfs_pgrb2_global_forecast_recompute_0.25degree\n",
    "HIRLAM -- http://data.planetos.com/datasets/fmi_hirlam_surface\n",
    "HARMONIE -- http://data.planetos.com/datasets/metno_harmonie_metcoop\n",
    "\n",
    "You can get more information about the datasets by opening links to their detail pages, but their main difference is that GFS is a global, medium range weather forecast model with lower resolution, and HIRLAM and HARMONIE are limited area models, meaning they cover only small part of the globe, but provide higher resolution of all forecasted field, in return.\n",
    "\n",
    "First we compare the datasets by showing their spatial coverages, then we demonstrate their resolutions by showing forecast field as a discrete grid (so one can see the difference in grid cell size and resolved surface details) and finally we demonstrate plotting weather forecast for the same variable from three models. \n",
    "\n",
    "We try to keep this demo short, but in case you are interested in creating a more interactive notebook, please refer to our other examples:\n",
    "https://github.com/planet-os/demos/blob/master/notebooks/PlanetOS_WAve_Models.ipynb\n",
    "https://github.com/planet-os/notebooks/blob/master/api-examples/GFS_public_full_demo_main.ipynb\n",
    "\n",
    "Unlike previous notebooks, we have moved most of the parsing code to external library dh_py_access, which you should get automatically if you get this notebook by cloning the git repository. \n",
    "\n",
    "If you have any questions, contact our team at https://data.planetos.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, let's import some modules. If you do not have them, download them (ie. using pip or conda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import warnings\n",
    "import dateutil.parser\n",
    "import matplotlib\n",
    "warnings.filterwarnings(\"ignore\",category=matplotlib.cbook.mplDeprecation)\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import datahub parsing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dh_py_access.lib.dataset import dataset as dataset\n",
    "import dh_py_access.lib.datahub as datahub\n",
    "from dh_py_access import package_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define hirlam and harmonie namespaces. Add server address and our API key. \n",
    "<font color='red'>Please add your API key below:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "server = 'http://api.planetos.com/v1/datasets/'\n",
    "API_key = open('APIKEY').read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dh=datahub.datahub_main(API_key)\n",
    "fmi_hirlam_surface=dataset('fmi_hirlam_surface',dh)\n",
    "metno_harmonie_metcoop=dataset('metno_harmonie_metcoop',dh)\n",
    "gfs=dataset('noaa_gfs_pgrb2_global_forecast_recompute_0.25degree',dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can easily see what kind of variables are available in given dataset by just calling methods:\n",
    "\n",
    "1. long_names -- gives a long human readable name for variable, which is unfortunately not standardised in any way\n",
    "2. standard_names -- gives variable names as defined in CF convention standard name table http://cfconventions.org/standard-names.html\n",
    "3. variable_names -- names by which you can actually query data from the API\n",
    "\n",
    "on a given dataset instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_var_names = {fmi_hirlam_surface:'Temperature_height_above_ground',\n",
    "                    metno_harmonie_metcoop:'air_temperature_2m',\n",
    "                    gfs:'tmp_m'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max_coverage_package(dataset, area_name, varfilter = 'temp'):\n",
    "    \"\"\"Download full coverage for limited area datasets\"\"\"\n",
    "    coords = dataset.get_dataset_boundaries()\n",
    "    ds_west = np.amin([i[0] for i in coords])\n",
    "    ds_east = np.amax([i[0] for i in coords])\n",
    "    ds_south = np.amin([i[1] for i in coords])\n",
    "    ds_north = np.amax([i[1] for i in coords])\n",
    "    temperature_variable = sample_var_names[dataset]\n",
    "    assert len(temperature_variable) >= 1, \"something wrong {0}\".format(temperature_variable)\n",
    "    assert type(temperature_variable) == str\n",
    "    return package_api.package_api(dh,dataset.datasetkey,temperature_variable,ds_west,ds_east,ds_south,ds_north,area_name=area_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "area_name = 'maximum_04'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_harmonie = get_max_coverage_package(metno_harmonie_metcoop, area_name=area_name)\n",
    "package_fmi_hirlam = get_max_coverage_package(fmi_hirlam_surface, area_name=area_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'packageSubmitted': True, 'packageStatus': {'message': 'success'}, 'packageResult': {'success': True}}\n",
      "Package exists\n",
      "{'packageSubmitted': True, 'packageStatus': {'message': \"Internal error: Ran out of memory trying to read HDF5 filtered chunk. Either increase the JVM's heap size (use the -Xmx switch) or reduce the size of the dataset's chunks (use nccopy -c).\"}, 'packageResult': {'success': False}}\n",
      "http://api.planetos.com/v1/packages?apikey=8428878e4b944abeb84790e832c633fc&dataset=fmi_hirlam_surface&package=fmi_hirlam_surface_recent_reftime_20180717_maximum_04&var=Temperature_height_above_ground&z=all&polygon=%5B%5B-180.0%2C+25.579499999999999%5D%2C+%5B180.0%2C+25.579499999999999%5D%2C+%5B180.0%2C+90.0%5D%2C+%5B-180.0%2C+90.0%5D%2C+%5B-180.0%2C+25.579499999999999%5D%5D&reftime_recent=true\n"
     ]
    }
   ],
   "source": [
    "package_harmonie.make_package()\n",
    "package_fmi_hirlam.make_package()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already downloaded\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Package creation failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c271e687e804>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpackage_harmonie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpackage_fmi_hirlam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/etoodu/Desktop/planetOS/git/notebooks/api-examples/dh_py_access/package_api.py\u001b[0m in \u001b[0;36mdownload_package\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File already downloaded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_package_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_download_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/etoodu/Desktop/planetOS/git/notebooks/api-examples/dh_py_access/package_api.py\u001b[0m in \u001b[0;36mwait_for_package_completion\u001b[0;34m(self, maxtime)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Package creation failed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Package creation failed"
     ]
    }
   ],
   "source": [
    "package_harmonie.download_package()\n",
    "package_fmi_hirlam.download_package()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_harmonie = xr.open_dataset(package_harmonie.get_local_file_name())\n",
    "data_fmi_hirlam = xr.open_dataset(package_fmi_hirlam.get_local_file_name(),decode_cf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take GFS for area of HARMONIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left = np.amin(data_harmonie['lon'].data)\n",
    "right = np.amax(data_harmonie['lon'].data)\n",
    "bottom = np.amin(data_harmonie['lat'].data)\n",
    "top = np.amax(data_harmonie['lat'].data)\n",
    "\n",
    "package_gfs = package_api.package_api(dh,gfs.datasetkey,sample_var_names[gfs],left,right,bottom,top,area_name=area_name)\n",
    "package_gfs.make_package()\n",
    "package_gfs.download_package()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_gfs = xr.open_dataset(package_gfs.get_local_file_name(),decode_cf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset extent and resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some arbitrary field for demonstration, we use 2m temperature and as you can see, variable names may actually differ a lot between datasets. Please note that \"get_tds_field\" method is just for getting arbitrary preview image, if you wan't to query data for specific time and reftime, please refer to examples for our raster API (shown in other notebooks referenced to above) or use THREDDS server link given in dataset detail pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extent\n",
    "The easiest way to show dataset extent is to plot it on a map with proper projection. We do not show GFS here, because, well, it is global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = Basemap(projection='ortho',lon_0=10,lat_0=50,resolution='l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hir_x,hir_y=np.meshgrid(data_fmi_hirlam['lon'],data_fmi_hirlam['lat'])\n",
    "X_hir,Y_hir=m(hir_x,hir_y)\n",
    "fig=plt.figure()\n",
    "plt.subplot(221)\n",
    "air2d = data_fmi_hirlam[sample_var_names[fmi_hirlam_surface]][0,0,:,:]\n",
    "air2d = np.ma.masked_where(air2d>500,air2d)\n",
    "m.pcolormesh(X_hir,Y_hir,air2d)\n",
    "m.drawcoastlines()\n",
    "plt.subplot(222)\n",
    "harm_x,harm_y=np.meshgrid(data_harmonie.lon,data_harmonie.lat)\n",
    "X_harm,Y_harm=m(harm_x,harm_y)\n",
    "m.pcolormesh(X_harm,Y_harm,data_harmonie[sample_var_names[metno_harmonie_metcoop]][0,0,:,:])\n",
    "m.drawcoastlines()\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's zoom in a little to illustrate difference in resolutions. By plotting the gridded data as a mesh, one can easily get the grid size from the figures. Plot's given for the Norwegian coast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lon1,lon2=5,7\n",
    "lat1,lat2 = 58,59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m2 = Basemap(projection='merc',llcrnrlat=lat1,urcrnrlat=lat2,\\\n",
    "            llcrnrlon=lon1,urcrnrlon=lon2,lat_ts=58,resolution='i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(8,8))\n",
    "plt.subplot(221)\n",
    "\n",
    "## we cannot use .sel() method on hirlam data because \n",
    "##it was opened with decode_cf=False \n",
    "## which was because it contains both missing_value and fill_value, see https://github.com/pydata/xarray/issues/1749\n",
    "x1 = np.argmin(np.abs(data_fmi_hirlam.lon-360-lon1)).data\n",
    "x2 = np.argmin(np.abs(data_fmi_hirlam.lon-360-lon2)).data+1\n",
    "y1 = np.argmin(np.abs(data_fmi_hirlam.lat-lat1)).data\n",
    "y2 = np.argmin(np.abs(data_fmi_hirlam.lat-lat2)).data+1\n",
    "height = int(np.argmin(np.abs(data_fmi_hirlam.height_above_ground-2)).data)\n",
    "hir_x,hir_y=np.meshgrid(data_fmi_hirlam.lon[x1:x2].data,data_fmi_hirlam.lat[y1:y2].data)\n",
    "X,Y=m2(hir_x-360,hir_y)\n",
    "air2d_hirlam=data_fmi_hirlam.variables[sample_var_names[fmi_hirlam_surface]].isel(time=0,height_above_ground=height,lon=slice(x1,x2),lat=slice(y1,y2))\n",
    "m2.pcolormesh(X,Y,air2d_hirlam)\n",
    "m2.drawcoastlines()\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(222)\n",
    "X,Y=m2(harm_x,harm_y)\n",
    "air2d_harm = data_harmonie[sample_var_names[metno_harmonie_metcoop]].isel(time=0).sel(height1=2,lon=slice(lon1,lon2),lat=slice(lat1,lat2))\n",
    "X,Y=m2(air2d_harm.lon.data,air2d_harm.lat.data)\n",
    "m2.pcolormesh(X,Y,air2d_harm)\n",
    "m2.drawcoastlines()\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(223)\n",
    "ggg = data_gfs[sample_var_names[gfs]].isel(time1=0).sel(height_above_ground2=2,lon=slice(lon1,lon2),lat=slice(lat2,lat1))\n",
    "x,y=np.meshgrid(ggg.lon,ggg.lat)\n",
    "X,Y=m2(x,y)\n",
    "m2.pcolormesh(X,Y,ggg)\n",
    "m2.drawcoastlines()\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you guess which model is on which map by just looking at these images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast for a single location\n",
    "First, get point data for all datasets for given variable and for as long time range as the forecast goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "longitude=26\n",
    "latitude=58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_point_data = [(k,k.get_json_data_in_pandas(**{'var':v,'lon':longitude,'lat':latitude,'count':1000})) for k,v in sample_var_names.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11,6))\n",
    "for ddd in sample_point_data:\n",
    "    zlevels = [2.]\n",
    "    for i in zlevels:\n",
    "        pdata=np.array(ddd[1][ddd[1]['z']==i][sample_var_names[ddd[0]]],dtype=np.float)\n",
    "        if np.sum(np.isnan(pdata))!=pdata.shape[0]:\n",
    "            plt.plot(ddd[1][ddd[1]['z']==i]['time'].apply(dateutil.parser.parse),pdata,label=str(i) + \"_\" + ddd[0].datasetkey)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "fig.autofmt_xdate()\n",
    "plt.title('2m temperature forecast in different weather models')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

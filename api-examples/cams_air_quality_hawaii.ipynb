{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the Air Pollution Spike Caused by the Thomas Fire\n",
    "\n",
    "The ongoing __[*Thomas Fire*](https://en.wikipedia.org/wiki/Thomas_Fire)__ north of Los Angeles has already burned across 270,000 acres and is causing hazardous air pollution in the region. In light of that, we’ve added a __[high-quality global air pollution dataset](http://data.planetos.com/datasets/cams_nrt_forecasts_global)__ to the Planet OS Datahub that provides a 5-day air quality forecast.\n",
    "\n",
    "The Copernicus Atmosphere Monitoring Service uses a comprehensive global monitoring and forecasting system that estimates the state of the atmosphere on a daily basis, combining information from models and observations, to provide a daily 5-day global surface forecast. \n",
    "\n",
    "The __[Planet OS Datahub](http://data.planetos.com)__ provides 28 different variables from the CAMS Air Quality Forecast dataset. I’ve used PM2.5 in my analysis of the Thomas Fire as these particles, often described as the fine particles, are up to 30 times smaller than the width of a human hair. These tiny particles are small enough to be breathed deep into the lungs, making them very dangerous to people’s health.\n",
    "\n",
    "As we would like to have data about the Continental United States we will download data by using Package API. Then we will create a widget where you can choose timestamp by using a slider. After that, we will also save the same data as a GIF to make sharing the results with friends and colleagues more fun. And finally, we make a plot from the specific location where the wildfires are occuring right now - __[Santa Barbara, California](http://edition.cnn.com/2017/12/14/us/california-fires/index.html)__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import dh_py_access.lib.datahub as datahub\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import dh_py_access.package_api as package_api\n",
    "import matplotlib.colors as colors\n",
    "import warnings\n",
    "import shutil\n",
    "import imageio\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Please put your datahub API key into a file called APIKEY and place it to the notebook folder or assign your API key directly to the variable API_key!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "server = 'api.planetos.com'\n",
    "API_key = open('APIKEY').readlines()[0].strip() #'<YOUR API KEY HERE>'\n",
    "version = 'v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, we need to define the dataset name and a variable we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dh = datahub.datahub(server,version,API_key)\n",
    "dataset = 'cams_nrt_forecasts_global'\n",
    "variable_name1 = 'pm2p5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define spatial range. We decided to analyze US, where unfortunately catastrofic wildfires are taking place at the moment and influeces air quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "area_name = 'HAWAII'\n",
    "latitude_north = 24; longitude_west = -170\n",
    "latitude_south = 15; longitude_east = -153"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data with package API\n",
    "\n",
    "1. Create package objects\n",
    "2. Send commands for the package creation\n",
    "3. Download the package files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "package_cams = package_api.package_api(dh,dataset,variable_name1,longitude_west,longitude_east,latitude_south,latitude_north,area_name=area_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'packageSubmitted': True}\n"
     ]
    }
   ],
   "source": [
    "package_cams.make_package()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package was not downloaded and error was not detected. It is safe to run \"download_package\" function as many times as needed.\n"
     ]
    }
   ],
   "source": [
    "package_cams.download_package()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work with the downloaded files\n",
    "\n",
    "We start with opening the files with xarray and adding PM2.5 as micrograms per cubic meter as well to make the values easier to understand and compare. After that, we will create a map plot with a time slider, then make a GIF using the images, and finally, we will look into a specific location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'/Users/etoodu/Desktop/planetOS/git/notebooks/api-examples/cams_nrt_forecasts_global_recent_reftime_20180720_HAWAII.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e3f17a7b40c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdd1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_cams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdd1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'longitude'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdd1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlongitude\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m360\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m180\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdd1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pm2p5_micro'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpm2p5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000000000.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdd1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpm2p5_micro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdd1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpm2p5_micro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/etoodu/anaconda/envs/py36/lib/python3.6/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, group, decode_cf, mask_and_scale, decode_times, autoclose, concat_characters, decode_coords, engine, chunks, lock, cache, drop_variables)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'netcdf4'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             store = backends.NetCDF4DataStore(filename_or_obj, group=group,\n\u001b[0;32m--> 282\u001b[0;31m                                               autoclose=autoclose)\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'scipy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             store = backends.ScipyDataStore(filename_or_obj,\n",
      "\u001b[0;32m/Users/etoodu/anaconda/envs/py36/lib/python3.6/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, format, group, writer, clobber, diskless, persist, autoclose)\u001b[0m\n\u001b[1;32m    208\u001b[0m                                    \u001b[0mdiskless\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiskless\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                                    format=format)\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_autoclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoclose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_isopen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/etoodu/anaconda/envs/py36/lib/python3.6/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m_open_netcdf4_group\u001b[0;34m(filename, mode, group, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mnetCDF4\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnc4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mclose_on_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'/Users/etoodu/Desktop/planetOS/git/notebooks/api-examples/cams_nrt_forecasts_global_recent_reftime_20180720_HAWAII.nc'"
     ]
    }
   ],
   "source": [
    "dd1 = xr.open_dataset(package_cams.local_file_name)\n",
    "dd1['longitude'] = ((dd1.longitude+180) % 360) - 180\n",
    "dd1['pm2p5_micro'] = dd1.pm2p5 * 1000000000.\n",
    "dd1.pm2p5_micro.data[dd1.pm2p5_micro.data < 0] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are making a Basemap of the US that we will use for showing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = Basemap(projection='merc', lat_0 = 55, lon_0 = -4,\n",
    "         resolution = 'i', area_thresh = 0.05,\n",
    "         llcrnrlon=longitude_west, llcrnrlat=latitude_south,\n",
    "         urcrnrlon=longitude_east, urcrnrlat=latitude_north)\n",
    "lons,lats = np.meshgrid(dd1.longitude.data,dd1.latitude.data)\n",
    "lonmap,latmap = m(lons,lats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now it is time to plot all the data. A great way to do it is to make an interactive widget, where you can choose time stamp by using a slider. \n",
    "\n",
    "As the minimum and maximum values are very different, we are using logarithmic colorbar to visualize it better.\n",
    "\n",
    "On the map we can see that the areas near Los Angeles have very high PM2.5 values due to the __[*Thomas Fire*](https://en.wikipedia.org/wiki/Thomas_Fire)__. By using the slider we can see the air quality forecast, which shows how the pollution is expected to expand. \n",
    "\n",
    "We are also adding a red dot to the map to mark the area, where the PM2.5 is the highest. Seems like most of the time it is near the Thomas Fire. We can also see that most of the Continental US is having PM2.5 values below the standard, which is 25 µg/m3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmax = 200#np.nanmax(dd1.pm2p5_micro.data)\n",
    "vmin = 1\n",
    "print (np.nanmax(dd1.pm2p5_micro.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadimg(k):\n",
    "    fig=plt.figure(figsize=(10,7))\n",
    "    ax = fig.add_subplot(111)\n",
    "    pcm = m.pcolormesh(lonmap,latmap,dd1.pm2p5_micro.data[k],\n",
    "                norm = colors.LogNorm(vmin=vmin, vmax=vmax),cmap = 'rainbow')\n",
    "    ilat,ilon = np.unravel_index(np.nanargmax(dd1.pm2p5_micro.data[k]),dd1.pm2p5_micro.data[k].shape)\n",
    "    m.plot(lonmap[ilat,ilon],latmap[ilat,ilon],'ro')\n",
    "    m.drawcoastlines()\n",
    "    m.drawcountries()\n",
    "    m.drawstates()\n",
    "    cbar = plt.colorbar(pcm,fraction=0.02, pad=0.040,ticks=[10**0, 10**1, 10**2])\n",
    "    cbar.ax.set_yticklabels([0,10,100]) \n",
    "    plt.title(str(dd1.pm2p5_micro.time[k].data)[:-10])\n",
    "    cbar.set_label('micrograms m^3')\n",
    "    print(\"Maximum: \",\"%.2f\" % np.nanmax(dd1.pm2p5_micro.data[k]))\n",
    "\n",
    "    plt.show()\n",
    "widgets.interact(loadimg, k=widgets.IntSlider(min=0,max=(len(dd1.pm2p5_micro.data)-1),step=1,value=0, layout=widgets.Layout(width='100%')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's include an image from the last time-step as well, because GitHub Preview doesn't show the time slider images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadimg(120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the function below we will save images you saw above to the local filesystem as a GIF, so it is easily shareable with others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ani():\n",
    "    folder = './anim/'\n",
    "    for k in range(len(dd1.pm2p5_micro)):\n",
    "        filename = folder + 'ani_' + str(k).rjust(3,'0') + '.png'\n",
    "        if not os.path.exists(filename):\n",
    "            fig=plt.figure(figsize=(10,7))\n",
    "            ax = fig.add_subplot(111)\n",
    "            pcm = m.pcolormesh(lonmap,latmap,dd1.pm2p5_micro.data[k],\n",
    "                        norm = colors.LogNorm(vmin=vmin, vmax=vmax),cmap = 'rainbow')\n",
    "            m.drawcoastlines()\n",
    "            m.drawcountries()\n",
    "            m.drawstates()\n",
    "            cbar = plt.colorbar(pcm,fraction=0.02, pad=0.040,ticks=[10**0, 10**1, 10**2])\n",
    "            cbar.ax.set_yticklabels([0,10,100]) \n",
    "            plt.title(str(dd1.pm2p5_micro.time[k].data)[:-13] + ' Max: ' + \"%.2f\" % np.nanmax(dd1.pm2p5_micro.data[k]))\n",
    "            ax.set_xlim()\n",
    "            cbar.set_label('micrograms m^3')\n",
    "            if not os.path.exists(folder):\n",
    "                os.mkdir(folder)\n",
    "            plt.savefig(filename,bbox_inches = 'tight')\n",
    "            plt.close()\n",
    "\n",
    "    files = sorted(os.listdir(folder))\n",
    "    images = []\n",
    "    for file in files:\n",
    "        if not file.startswith('.'):\n",
    "            filename = folder + file\n",
    "            images.append(imageio.imread(filename))\n",
    "    kargs = { 'duration': 0.1,'quantizer':2,'fps':5.0}\n",
    "    imageio.mimsave('cams_pm2p5.gif', images, **kargs)\n",
    "    print ('GIF is saved as cams_pm2p5.gif under current working directory')\n",
    "    shutil.rmtree(folder)\n",
    "make_ani()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To see data more specifically we need to choose the location. This time we decided to look into the place where PM2.5 is highest. Seems like at the moment it is the Santa Barbara area, where the Thomas Fire is taking place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilat,ilon = np.unravel_index(np.nanargmax(dd1.pm2p5_micro.data[1]),dd1.pm2p5_micro.data[1].shape)\n",
    "lon_max = dd1.longitude.data[ilon]; lat_max = dd1.latitude.data[ilat]\n",
    "data_in_spec_loc = dd1.sel(longitude = lon_max,latitude=lat_max,method='nearest')\n",
    "print ('Latitude ' + str(lat_max) + ' ; Longitude ' + str(lon_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot below we can see the PM2.5 forecast on the surface layer. Note that the time zone on the graph is UTC while the time zone in Santa Barbara is UTC-08:00. The air pollution from the wildfire has exceeded a record  5,000 µg/m3, while the hourly norm is 25 µg/m3. We can also see some peaks every day around 12 pm UTC (4 am PST) and the lowest values are around 12 am UTC (4 pm PST). \n",
    "\n",
    "Also, it is predicted that the pollution will start to go down on December the 21st. However, the values will continue to be very high during the night. This daily pattern where the air quality is the worst at night is caused by the __[*temperature inversion*](http://en.ilmatieteenlaitos.fi/temperature-inversions)__. As the land is not heated by the sun during the night, and the winds tend to be weaker as well, the pollution gets trapped near the ground. Pollution also tends to be higher in the winter time when the days are shorter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.plot(data_in_spec_loc.time,data_in_spec_loc.pm2p5_micro, '*-',linewidth = 1,c='blue',label = dataset) \n",
    "plt.xlabel('Time')\n",
    "plt.title('PM2.5 forecast for Santa Barbara')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will remove the package we downloaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.remove(package_cams.local_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
